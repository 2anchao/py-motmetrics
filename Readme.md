## py-motmetrics

The **py-motmetrics** library provides a Python implementation of metrics for benchmarking multiple object trackers (MOT).

While benchmarking single object trackers is rather straightforward, measuring the performance of multiple object trackers needs careful thinking as multiple correspondence constellation can arise (see image below). A variety of methods has been proposed in the past and while there is no general agreement, the methods of [[1,2,3]](#References) have received considerable attention in recent years. 

**py-motmetrics** provides these suggested metrics. The results generated by this implementation are compatible with popular [MOTChallenge][MOTChallenge] benchmarks.

![](etc/mot.png)<br/>
*Pictures courtesy of Bernardin, Keni, and Rainer Stiefelhagen [[1]](#References)*

### Features at a glance
- *Variety of metrics* <br/>
Provides MOTA, MOTP, track quality measures and more (see below).
- *Distance agnostic* <br/>
Supports Euclidean, Intersection over Union and other distances measures.
- *Complete event history* <br/> 
Tracks all relevant per-frame events suchs as correspondences, misses, false alarms and switches.
- *Easy to extend* <br/> 
Events and summaries are utilizing [pandas][pandas] for data structures and analysis.

<a name="Metrics"></a>
### Metrics

**py-motmetrics** implements the following metrics. The metrics have been aligned with what is reported by [MOTChallenge][MOTChallenge] benchmarks.

Metric  | Unit   | Description |
------- | ------ | ----------- |
Frames  | Count  | Total number of frames|
Match  | Count  | Total number matches|
Switch  | Count  | Total number track switches (see [[1]](#References))|
FalsePos  | Count  | Total number false positive hypothesis (see [[1]](#References))|
Miss  | Count  | Total number missed objects (see [[1]](#References))|
MOTP  | Distance  | Multiple Object Tracking Precision. Average distance error of correctly detected objects (see [[1]](#References)). Note, MOTChallenge compatibility is given by `MOTP=1-MOTP`, distance IoU with threshold 0.5|
MOTA  | Percentage  | Multiple object tracking accuracy (see [[1]](#References)). Accounts for object configuration errors of tracker.|
|Precision | Percentage | Percent of correct detections to total tracker detections (see [[2]](#References)).|
|Recall | Percentage | Percent of correct detections to total number of objects (see [[2]](#References)).|
|Frag | Count | Total number of track fragmentations (see [[2,3]](#References)). |
|Objs | Count | Total number unique objects. |
|MT | Count | Mostly tracked objects (see [[2,3]](#References)). Count of trajectories covered by hypothesis for at least 80% of track-lifespan.|
|PT | Count | Partially tracked objects (see [[2,3]](#References)). Count of trajectories covered by hypothesis between 20% and 80% of track-lifespan. |
|ML | Count | Mostly lost objects (see [[2,3]](#References)). Count of trajectories covered by hypothesis for less than 20% of track-lifespan.|

<a name="References"></a>
### References
1. Bernardin, Keni, and Rainer Stiefelhagen. "Evaluating multiple object tracking performance: the CLEAR MOT metrics." 
EURASIP Journal on Image and Video Processing 2008.1 (2008): 1-10.
2. Milan, Anton, et al. "Mot16: A benchmark for multi-object tracking." arXiv preprint arXiv:1603.00831 (2016).
3. Li, Yuan, Chang Huang, and Ram Nevatia. "Learning to associate: Hybridboosted multi-target tracker for crowded scene." 
Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. IEEE, 2009.

### Usage

#### Populating the accumulator

```python
import motmetrics as mm

# Create an accumulator that will be updated during each frame
acc = mm.MOTAccumulator(auto_id=True)

# Call update once for per frame. For now, assume distances are between
# frame objects / hypotheses are given.
acc.update(
    ['a', 'b'],                 # Ground truth objects in this frame
    [1, 2, 3],                  # Detector hypotheses in this frame
    [
        [0.1, np.nan, 0.3],     # Distances from object 'a' to hypotheses 1, 2, 3
        [0.5,  0.2,   0.3]      # Distances from object 'b' to hypotheses 1, 2, 3
    ]
)
```

In the above code an event accumulator is created and updated for one frame. To inspect the current state simple print the events associated with the accumulator

```python
print(acc.events)
"""
                Type  OId HId    D
FrameId Event
0       0      MATCH    a   1  0.1
        1      MATCH    b   2  0.2
        2         FP  NaN   3  NaN
"""
```

Meaning object `a` was matched to hypothesis `1` with distance 0.1. Similarily, `b` was matched to `2` with distance 0.2. Hypothesis `3` could not be matched to any remaining object and generated a false positive (FP).

Continuing
```python
df = acc.update(
    ['a', 'b'],
    [1],
    [
        [0.2], 
        [0.4]
    ]
)
print(df)
"""
0      MATCH   a    1  0.2
1       MISS   b  NaN  NaN
"""
```

While `a` was matched, `b` couldn't be matched because of lacking hypotheses.

```python
df = acc.update(
    ['a', 'b'],
    [1, 3],
    [
        [0.6, 0.2],
        [0.1, 0.6]
    ]
)
print(df)
"""
0       MATCH   a   1  0.6
1      SWITCH   b   3  0.6
"""
```
`b` is now tracked by hypothesis `3` leading to a track switch.

#### Computing metrics
Once the accumulator has been populated you can compute and display metrics. Continuing the example from above

```python
summary = mm.metrics.summarize(acc)
print(mm.io.render_summary(summary))
"""
   Frames  Match  Switch  FalsePos  Miss  MOTP   MOTA Precision Recall  Frag  Objs  MT  PT  ML
0       3      4       1         1     1 0.340 50.00%    83.33% 83.33%     1     2   1   1   0
"""

# Summarize multiple accumulators or accumulator parts
summaries = mm.metrics.summarize([acc, acc.events.loc[0:1]], names=['full', 'part'])
print(mm.io.render_summary(summaries))
"""
      Frames  Match  Switch  FalsePos  Miss  MOTP   MOTA Precision Recall  Frag  Objs  MT  PT  ML
full       3      4       1         1     1 0.340 50.00%    83.33% 83.33%     1     2   1   1   0
part       2      3       0         1     1 0.167 50.00%    75.00% 75.00%     0     2   1   1   0
"""
```

### Installation
To install **py-motmetrics** clone this repository and use `pip` to install
from local sources.

```
pip install -e <path/to/setup.py>
```

Python 3.5/3.6 and numpy, pandas and scipy is required.

### Continuous Integration

Branch  | Status
------- | ------
master  | ![](https://travis-ci.org/cheind/py-motmetrics.svg?branch=master)
develop | ![](https://travis-ci.org/cheind/py-motmetrics.svg?branch=develop)


### License
MIT License

Copyright (c) 2017 Christoph Heindl

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



[Pandas]: http://pandas.pydata.org/
[MOTChallenge]: https://motchallenge.net/
